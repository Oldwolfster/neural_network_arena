import torch
import torch.nn as nn


class NonLinearRegressionModel(nn.Module):
    def __init__(self):
        super(NonLinearRegressionModel, self).__init__()
        self.model = nn.Sequential(
            nn.Linear(2, 16),
            nn.ReLU(),
            nn.Linear(16, 1)
        )

    def forward(self, x):
        return self.model(x)


InputsAndOutput= [(39.3774991105287, 3.2992939660241074, 718.667371079892), (28.48955905155273, 0.8883499432942816, 199.8110169865912), (35.64920254076503, 3.9655304100204063, 780.7766952735783), (17.49113712748217, 3.351638611615231, 374.12782005324704), (32.34349949194655, 0.09359566067823533, 91.97768888371668), (28.960283429666575, 5.250213522630987, 819.0270448417818), (21.660199252229976, 2.27231429383456, 306.72105400355883), (15.359769122616477, 3.222265148836394, 336.9616571449474), (26.594403874137132, 1.946787861658417, 327.4175206922974), (22.860674281540938, 0.40436425169231605, 109.92202606587472), (28.474077124727767, 3.7306741630355047, 591.6372636215596), (27.625714002522695, 3.9626775994826575, 660.1250469057272), (26.458820092465455, 0.4297894015574082, 123.04431975164397), (38.79591603565844, 4.277842630828401, 877.968759801366), (9.402778291548678, 0.00788578575838983, 36.57580190349703), (5.195370310401706, 0.8177734850616174, 72.61967014880162), (15.652068945010932, 7.9149064925389, 647.9962386926206), (31.072896695286328, 5.265875740485439, 905.794148653808), (8.925104704315565, 0.4688762221650471, 72.02561566053544), (13.820466018068384, 0.30417586870644353, 59.36044657107752), (22.736338034303444, 2.856100569381246, 411.407312274295), (19.578164509218485, 2.7091095461572374, 374.5822535614151), (7.754227183967779, 3.5361339081157075, 244.67943840919114), (2.5247139442059963, 5.059622482357053, 215.08979085740648), (18.9059075193013, 2.0228760800887944, 284.4662313560739), (26.53882709928752, 1.4208799921734272, 270.5114519930978), (13.044549976812302, 1.4653518976081203, 159.74796071829985), (24.697426399515233, 6.756303376024534, 895.6047717680751), (17.39610213479041, 6.016929797218957, 686.3796879216917), (27.953768240060764, 2.4243754496078136, 409.50341536910605), (18.097501203759204, 1.3176570197005129, 180.99626684612485), (35.36888460372005, 0.7519142001832888, 197.90154708541593), (30.8057805936704, 0.9624372879976892, 221.2063088418463), (29.191577901066793, 6.4720089591226575, 1046.1458527582229), (9.726981398124451, 1.8422914303612323, 165.36778055805723), (18.03075452785222, 2.6595587065311674, 311.560487024368), (38.427773599197515, 3.5980488328519833, 723.8399268499909), (26.46691413709989, 2.101376510933365, 347.3019599233438), (10.051332364593728, 4.073611711047465, 315.7323936005832), (39.07837896613052, 7.376848881737993, 1524.6673569633858), (26.96935970349491, 3.2552985432359343, 477.21850498771283), (10.62663878999825, 4.149862498402834, 338.3215769325481), (2.3488327937732434, 4.55924336180596, 203.63443085491497), (32.64688756230636, 6.078013348753597, 1062.5624410259104), (29.63262487758632, 6.667598427207722, 1073.713550659541), (15.998743097442372, 6.265424676559139, 655.788437664286), (39.84101808510846, 4.049929698732977, 869.7149743777752), (22.878266126885336, 7.507440670604848, 952.233057556996), (10.12209502562361, 0.48640648521876617, 63.01414832769935), (39.35975769620619, 1.6219041062826873, 396.9734246366061), (28.63570242270589, 2.1175574978022276, 394.8814495453983), (9.854856449985746, 7.793536486923424, 599.5365376412049), (25.152708505045922, 5.171972980163695, 727.3864152622284), (26.575331813179428, 3.6350576221863564, 548.4609373256675), (15.419404508719836, 4.476597333083491, 433.46075538213944), (17.953676923860705, 5.671384022660404, 614.094284875296), (23.637952554701474, 7.198496188276408, 939.8988619861778), (1.7381645561646675, 7.0022846650921355, 286.0438607217735), (7.476861258950875, 2.884526080175994, 213.28512542794604), (17.42194986951875, 3.8691213127901625, 436.802740201113), (11.845644888807158, 1.6257242419597322, 165.350466676513), (3.5704276001197144, 1.8559617929094845, 95.64477415070252), (28.702964505895654, 5.526410193402645, 856.9879002288905), (3.333234666606679, 4.355197589952795, 220.6283009526631), (26.32750984119101, 6.917500905054156, 999.4610847807547), (10.927725201101111, 0.02600374158965746, 48.0357136906681), (21.128591584979496, 7.311433939859127, 865.9353142142248), (24.396412874345017, 2.8307566268030513, 437.399137710658), (37.09059695209638, 0.17269528337877826, 117.3641747061259), (2.998426270371777, 6.174176449386129, 252.81015590134695), (34.52324503054169, 4.842429589368751, 951.696015766527), (26.02557761049226, 1.8499599246208502, 295.0508428341934), (19.588530644626694, 1.2908553796289102, 199.9630968882103), (22.45999278419566, 6.013375755737425, 806.7982788896356), (28.746008679246117, 0.12482681001229068, 88.28893314386272), (14.433157821026349, 7.950819937413745, 754.2999976256191), (23.304513873916626, 0.9564719646192934, 192.14874380586926), (34.30680579681744, 0.5715233872665717, 174.5063141224129), (15.51271126449356, 4.550089391946103, 476.9660845457793), (34.3612014203248, 7.93697292512513, 1380.0291012274367), (9.791522941208175, 6.822923293387346, 543.9227580202854), (36.51018472151443, 4.59363722074171, 877.1888570877081), (7.798237095195373, 4.443024488255889, 339.61378369810217), (3.7119906455763774, 4.935088841631132, 220.73449780408282), (36.90875709928332, 4.756358954216286, 922.3420911750552), (18.122900402644632, 3.5838219379954994, 427.8354156046064), (24.4676560632076, 2.458698269801432, 366.094671430967), (20.392667657092673, 7.540175864112275, 925.121076515782), (18.74318053891004, 1.310784764558794, 177.37354411090064), (20.04165671761758, 5.855470633960874, 735.0012430343864), (9.642109701748787, 6.399783660884454, 438.91304652564907), (17.676525212978483, 0.7558018034361753, 128.42141399970635), (4.889276602511026, 5.137179005206129, 277.078259495998), (5.749937172645083, 1.383335928812449, 95.40199692862701), (37.06596959417118, 5.458768835632083, 1075.2237596619088), (36.38840409488957, 5.638158747337844, 1094.7442488343122), (39.55222795756249, 2.2372780796293954, 509.33879144892535), (13.175736540370284, 5.445554694731518, 471.8098491801079), (8.439220920803479, 2.2922963447342415, 206.83568103917858), (26.40392334048491, 5.555194149601925, 775.1568854259725)]


# List with the first two elements of each tuple
x = [item[:2] for item in InputsAndOutput]

# List with the last element of each tuple
y = [item[2] for item in InputsAndOutput]


#X = torch.tensor([[1, 2], [3, 4], [5, 6]], dtype=torch.float32)
X = torch.tensor(x, dtype=torch.float32)
#y = torch.tensor([[10], [20], [30]], dtype=torch.float32)
Y=torch.tensor(y, dtype=torch.float32)

model = NonLinearRegressionModel()

criterion = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)


num_epochs = 1000
for epoch in range(num_epochs):
    # Forward pass
    outputs = model(X)
    loss = criterion(outputs, y)

    # Backward and optimize
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

    if (epoch+1) % 100 == 0:
        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')

        # Example input data

new_X = torch.tensor([[7, 8], [9, 10]], dtype=torch.float32)

# Get model predictions
predictions = model(new_X)
print(predictions)
'''
The key steps are:

Prepare the training data as PyTorch tensors
Initialize the model
Define the loss function and optimizer
Train the model by iterating through the training data, computing the loss, and updating the model parameters
Use the trained model to make predictions on new input data

This is a basic example, and in practice, you may want to add more features, such as validation, testing, and model evaluation. But this should give you an idea of how to work with the 
'''